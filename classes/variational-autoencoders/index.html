<!DOCTYPE html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Artificial Neural Networks and Deep Learning course at Insper"><meta name=author content="Sandmann, H."><link href=https://insper.github.io/ann-dl/classes/variational-autoencoders/ rel=canonical><link href=../generative-adversarial-networks/ rel=prev><link href=../clip/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.22"><title>14. VAE - Artificial Neural Networks and Deep Learning</title><link rel=stylesheet href=../../assets/stylesheets/main.84d31ad4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M64%20480c-35.3%200-64-28.7-64-64V96c0-35.3%2028.7-64%2064-64h320c35.3%200%2064%2028.7%2064%2064v213.5c0%2017-6.7%2033.3-18.7%2045.3L322.7%20461.3c-12%2012-28.3%2018.7-45.3%2018.7zm325.5-176H296c-13.3%200-24%2010.7-24%2024v93.5z%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M384%20512H96c-53%200-96-43-96-96V96C0%2043%2043%200%2096%200h304c26.5%200%2048%2021.5%2048%2048v288c0%2020.9-13.4%2038.7-32%2045.3V448c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032zM96%20384c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032h256v-64zm32-232c0%2013.3%2010.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24H152c-13.3%200-24%2010.7-24%2024m24%2072c-13.3%200-24%2010.7-24%2024s10.7%2024%2024%2024h176c13.3%200%2024-10.7%2024-24s-10.7-24-24-24z%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m-32-352a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200m-8%2064h48c13.3%200%2024%2010.7%2024%2024v88h8c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-80c-13.3%200-24-10.7-24-24s10.7-24%2024-24h24v-64h-24c-13.3%200-24-10.7-24-24s10.7-24%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M461.2%2018.9C472.7%2024%20480%2035.4%20480%2048v416c0%2012.6-7.3%2024-18.8%2029.1s-24.8%203.2-34.3-5.1l-46.6-40.7c-43.6-38.1-98.7-60.3-156.4-63V480c0%2017.7-14.3%2032-32%2032h-32c-17.7%200-32-14.3-32-32v-96C57.3%20384%200%20326.7%200%20256s57.3-128%20128-128h84.5c61.8-.2%20121.4-22.7%20167.9-63.3L427%2024c9.4-8.3%2022.9-10.2%2034.3-5.1zM224%20320v.2c70.3%202.7%20137.8%2028.5%20192%2073.4V118.3c-54.2%2044.9-121.7%2070.7-192%2073.4z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M434.8%2070.1c14.3%2010.4%2017.5%2030.4%207.1%2044.7l-256%20352c-5.5%207.6-14%2012.3-23.4%2013.1s-18.5-2.7-25.1-9.3l-128-128c-12.5-12.5-12.5-32.8%200-45.3s32.8-12.5%2045.3%200l101.5%20101.5%20234-321.7c10.4-14.3%2030.4-17.5%2044.7-7.1z%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%20512a256%20256%200%201%200%200-512%20256%20256%200%201%200%200%20512m0-336c-17.7%200-32%2014.3-32%2032%200%2013.3-10.7%2024-24%2024s-24-10.7-24-24c0-44.2%2035.8-80%2080-80s80%2035.8%2080%2080c0%2047.2-36%2067.2-56%2074.5v3.8c0%2013.3-10.7%2024-24%2024s-24-10.7-24-24v-8.1c0-20.5%2014.8-35.2%2030.1-40.2%206.4-2.1%2013.2-5.5%2018.2-10.3%204.3-4.2%207.7-10%207.7-19.6%200-17.7-14.3-32-32-32zm-32%20192a32%2032%200%201%201%2064%200%2032%2032%200%201%201-64%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M256%200c14.7%200%2028.2%208.1%2035.2%2021l216%20400c6.7%2012.4%206.4%2027.4-.8%2039.5S486.1%20480%20472%20480H40c-14.1%200-27.2-7.4-34.4-19.5s-7.5-27.1-.8-39.5l216-400c7-12.9%2020.5-21%2035.2-21m0%20352a32%2032%200%201%200%200%2064%2032%2032%200%201%200%200-64m0-192c-18.2%200-32.7%2015.5-31.4%2033.7l7.4%20104c.9%2012.5%2011.4%2022.3%2023.9%2022.3%2012.6%200%2023-9.7%2023.9-22.3l7.4-104c1.3-18.2-13.1-33.7-31.4-33.7z%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20576%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M480-16c6.9%200%2013%204.4%2015.2%2010.9l13.5%2040.4%2040.4%2013.5C555.6%2051%20560%2057.1%20560%2064s-4.4%2013-10.9%2015.2l-40.4%2013.5-13.5%2040.4c-2.2%206.5-8.3%2010.9-15.2%2010.9s-13-4.4-15.2-10.9l-13.5-40.4-40.4-13.5C404.4%2077%20400%2070.9%20400%2064s4.4-13%2010.9-15.2l40.4-13.5%2013.5-40.4C467-11.6%20473.1-16%20480-16M321.4%2097.4c12.5-12.5%2032.8-12.5%2045.3%200l80%2080c12.5%2012.5%2012.5%2032.8%200%2045.3l-10.9%2010.9c7.9%2022%2012.2%2045.7%2012.2%2070.5%200%20114.9-93.1%20208-208%20208S32%20418.9%2032%20304%20125.1%2096%20240%2096c24.7%200%2048.5%204.3%2070.5%2012.3zM144%20304c0-53%2043-96%2096-96%2013.3%200%2024-10.7%2024-24s-10.7-24-24-24c-79.5%200-144%2064.5-144%20144%200%2013.3%2010.7%2024%2024%2024s24-10.7%2024-24%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20512%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M416%20427.4c58.5-44%2096-111.6%2096-187.4C512%20107.5%20397.4%200%20256%200S0%20107.5%200%20240c0%2075.8%2037.5%20143.4%2096%20187.4V464c0%2026.5%2021.5%2048%2048%2048h32v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h64v-40c0-13.3%2010.7-24%2024-24s24%2010.7%2024%2024v40h32c26.5%200%2048-21.5%2048-48zM96%20256a64%2064%200%201%201%20128%200%2064%2064%200%201%201-128%200m256-64a64%2064%200%201%201%200%20128%2064%2064%200%201%201%200-128%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20640%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M352%200c0-17.7-14.3-32-32-32s-32%2014.3-32%2032v64h-96c-53%200-96%2043-96%2096v224c0%2053%2043%2096%2096%2096h256c53%200%2096-43%2096-96V160c0-53-43-96-96-96h-96zM160%20368c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24m120%200c0-13.3%2010.7-24%2024-24h32c13.3%200%2024%2010.7%2024%2024s-10.7%2024-24%2024h-32c-13.3%200-24-10.7-24-24M224%20176a48%2048%200%201%201%200%2096%2048%2048%200%201%201%200-96m144%2048a48%2048%200%201%201%2096%200%2048%2048%200%201%201-96%200m-304%200c0-17.7-14.3-32-32-32S0%20206.3%200%20224v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32zm544-32c-17.7%200-32%2014.3-32%2032v96c0%2017.7%2014.3%2032%2032%2032s32-14.3%2032-32v-96c0-17.7-14.3-32-32-32%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M288%200H128c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032v151.5L7.5%20426.3C2.6%20435%200%20444.7%200%20454.7%200%20486.4%2025.6%20512%2057.3%20512h333.4c31.6%200%2057.3-25.6%2057.3-57.3%200-10-2.6-19.8-7.5-28.4L320%20215.5V64c17.7%200%2032-14.3%2032-32S337.7%200%20320%200zm-96%20215.5V64h64v151.5c0%2011.1%202.9%2022.1%208.4%2031.8L306%20320H142l41.6-72.7c5.5-9.7%208.4-20.6%208.4-31.8%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20448%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%207.1.0%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202025%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M0%20216C0%20149.7%2053.7%2096%20120%2096h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064H64c-35.3%200-64-28.7-64-64zm256%200c0-66.3%2053.7-120%20120-120h8c17.7%200%2032%2014.3%2032%2032s-14.3%2032-32%2032h-8c-30.9%200-56%2025.1-56%2056v8h64c35.3%200%2064%2028.7%2064%2064v64c0%2035.3-28.7%2064-64%2064h-64c-35.3%200-64-28.7-64-64z%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_markdown_exec_pyodide.css><link rel=stylesheet href=../../assets/stylesheets/neoteroi-mkdocs.min.css><link rel=stylesheet href=../../assets/stylesheets/neoteroi-timeline.css><link rel=stylesheet href=../../assets/stylesheets/extra.css><link rel=stylesheet href=../../assets/stylesheets/badge.css><link rel=stylesheet href=../../termynal.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#autoencoders class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Artificial Neural Networks and Deep Learning" class="md-header__button md-logo" aria-label="Artificial Neural Networks and Deep Learning" data-md-component=logo> <img src=../../assets/images/ann-dl.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Artificial Neural Networks and Deep Learning </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 14. VAE </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"></path></svg> </label> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"></path></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_3 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"></path></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=grey data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_3> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/insper/ann-dl title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> insper/ann-dl </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Artificial Neural Networks and Deep Learning" class="md-nav__button md-logo" aria-label="Artificial Neural Networks and Deep Learning" data-md-component=logo> <img src=../../assets/images/ann-dl.png alt=logo> </a> Artificial Neural Networks and Deep Learning </label> <div class=md-nav__source> <a href=https://github.com/insper/ann-dl title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> insper/ann-dl </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Ementa </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/ class=md-nav__link> <span class=md-ellipsis> 2025.2 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Classes </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Classes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../concepts/ class=md-nav__link> <span class=md-ellipsis> 1. Concepts </span> </a> </li> <li class=md-nav__item> <a href=../data/ class=md-nav__link> <span class=md-ellipsis> 2. Data </span> </a> </li> <li class=md-nav__item> <a href=../preprocessing/ class=md-nav__link> <span class=md-ellipsis> 3. Preprocessing </span> </a> </li> <li class=md-nav__item> <a href=../ann/ class=md-nav__link> <span class=md-ellipsis> 4. Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../perceptron/ class=md-nav__link> <span class=md-ellipsis> 5. Perceptron </span> </a> </li> <li class=md-nav__item> <a href=../mlp/ class=md-nav__link> <span class=md-ellipsis> 6. Multi-Layer Perceptron </span> </a> </li> <li class=md-nav__item> <a href=../optimization/ class=md-nav__link> <span class=md-ellipsis> 7. Optimization </span> </a> </li> <li class=md-nav__item> <a href=../regularization/ class=md-nav__link> <span class=md-ellipsis> 8. Regularization </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <label class=md-nav__link for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class=md-ellipsis> 9. Metrics and Evaluation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> 9. Metrics and Evaluation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metrics/classification/ class=md-nav__link> <span class=md-ellipsis> 9.1. Classification </span> </a> </li> <li class=md-nav__item> <a href=../metrics/regression/ class=md-nav__link> <span class=md-ellipsis> 9.2. Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../deep-learning/ class=md-nav__link> <span class=md-ellipsis> 10. Deep Learning </span> </a> </li> <li class=md-nav__item> <a href=../convolutional-neural-networks/ class=md-nav__link> <span class=md-ellipsis> 11. Convolutional </span> </a> </li> <li class=md-nav__item> <a href=../generative-models/ class=md-nav__link> <span class=md-ellipsis> 12. Generative Models </span> </a> </li> <li class=md-nav__item> <a href=../generative-adversarial-networks/ class=md-nav__link> <span class=md-ellipsis> 13. GAN </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 14. VAE </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 14. VAE </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#autoencoders class=md-nav__link> <span class=md-ellipsis> Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#types-of-autoencoder class=md-nav__link> <span class=md-ellipsis> Types of Autoencoder </span> </a> <nav class=md-nav aria-label="Types of Autoencoder"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#vanilla-autoencoders class=md-nav__link> <span class=md-ellipsis> Vanilla Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#convolutional-autoencoders class=md-nav__link> <span class=md-ellipsis> Convolutional Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#variational-autoencoders class=md-nav__link> <span class=md-ellipsis> Variational Autoencoders </span> </a> <nav class=md-nav aria-label="Variational Autoencoders"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-features-of-vaes class=md-nav__link> <span class=md-ellipsis> Key Features of VAEs </span> </a> </li> <li class=md-nav__item> <a href=#training-vaes class=md-nav__link> <span class=md-ellipsis> Training VAEs </span> </a> </li> <li class=md-nav__item> <a href=#reparameterization-trick class=md-nav__link> <span class=md-ellipsis> Reparameterization Trick </span> </a> </li> <li class=md-nav__item> <a href=#numerical-simulation class=md-nav__link> <span class=md-ellipsis> Numerical Simulation </span> </a> <nav class=md-nav aria-label="Numerical Simulation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-architecture class=md-nav__link> <span class=md-ellipsis> Model Architecture </span> </a> </li> <li class=md-nav__item> <a href=#weights-and-biases class=md-nav__link> <span class=md-ellipsis> Weights and Biases </span> </a> </li> <li class=md-nav__item> <a href=#forward-pass class=md-nav__link> <span class=md-ellipsis> Forward Pass </span> </a> </li> <li class=md-nav__item> <a href=#loss-calculation class=md-nav__link> <span class=md-ellipsis> Loss Calculation </span> </a> </li> <li class=md-nav__item> <a href=#backward-pass class=md-nav__link> <span class=md-ellipsis> Backward Pass </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#additional class=md-nav__link> <span class=md-ellipsis> Additional </span> </a> <nav class=md-nav aria-label=Additional> <ul class=md-nav__list> <li class=md-nav__item> <a href=#relation-between-log-variance-and-standard-deviation class=md-nav__link> <span class=md-ellipsis> Relation between Log Variance and Standard Deviation </span> </a> <nav class=md-nav aria-label="Relation between Log Variance and Standard Deviation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-definitions class=md-nav__link> <span class=md-ellipsis> 1. Definitions </span> </a> </li> <li class=md-nav__item> <a href=#2-log-variance class=md-nav__link> <span class=md-ellipsis> 2. Log variance </span> </a> </li> <li class=md-nav__item> <a href=#3-relationship-between-log-variance-and-std class=md-nav__link> <span class=md-ellipsis> 3. Relationship between log variance and std </span> </a> </li> <li class=md-nav__item> <a href=#4-why-use-log-variance class=md-nav__link> <span class=md-ellipsis> 4. Why use log variance? </span> </a> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../clip/ class=md-nav__link> <span class=md-ellipsis> 15. CLIP </span> </a> </li> <li class=md-nav__item> <a href=../stable-diffusion/ class=md-nav__link> <span class=md-ellipsis> 16. Stable Diffusion </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Definitions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Definitions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../definitions/latent_space_vs_embedding/ class=md-nav__link> <span class=md-ellipsis> Latent Space vs. Embedding </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../references/ class=md-nav__link> <span class=md-ellipsis> References </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Versions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Versions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../versions/terms-and-conditions/ class=md-nav__link> <span class=md-ellipsis> Terms and Conditions </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex=0> <span class=md-ellipsis> 2025.2 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> 2025.2 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../versions/2025.2/ class=md-nav__link> <span class=md-ellipsis> 2025.2 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2_2> <label class=md-nav__link for=__nav_6_2_2 id=__nav_6_2_2_label tabindex=0> <span class=md-ellipsis> Exercises </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2_2> <span class="md-nav__icon md-icon"></span> Exercises </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../versions/2025.2/exercises/data/ class=md-nav__link> <span class=md-ellipsis> 1. Data </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/exercises/perceptron/ class=md-nav__link> <span class=md-ellipsis> 2. Perceptron </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/exercises/mlp/ class=md-nav__link> <span class=md-ellipsis> 3. MLP </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/exercises/vae/ class=md-nav__link> <span class=md-ellipsis> 4. VAE </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2_3> <label class=md-nav__link for=__nav_6_2_3 id=__nav_6_2_3_label tabindex=0> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2_3> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../versions/2025.2/projects/classification/ class=md-nav__link> <span class=md-ellipsis> 1. Classification </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/projects/regression/ class=md-nav__link> <span class=md-ellipsis> 2. Regression </span> </a> </li> <li class=md-nav__item> <a href=../../versions/2025.2/projects/generative/ class=md-nav__link> <span class=md-ellipsis> 3. Generative </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#autoencoders class=md-nav__link> <span class=md-ellipsis> Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#types-of-autoencoder class=md-nav__link> <span class=md-ellipsis> Types of Autoencoder </span> </a> <nav class=md-nav aria-label="Types of Autoencoder"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#vanilla-autoencoders class=md-nav__link> <span class=md-ellipsis> Vanilla Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#convolutional-autoencoders class=md-nav__link> <span class=md-ellipsis> Convolutional Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#variational-autoencoders class=md-nav__link> <span class=md-ellipsis> Variational Autoencoders </span> </a> <nav class=md-nav aria-label="Variational Autoencoders"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-features-of-vaes class=md-nav__link> <span class=md-ellipsis> Key Features of VAEs </span> </a> </li> <li class=md-nav__item> <a href=#training-vaes class=md-nav__link> <span class=md-ellipsis> Training VAEs </span> </a> </li> <li class=md-nav__item> <a href=#reparameterization-trick class=md-nav__link> <span class=md-ellipsis> Reparameterization Trick </span> </a> </li> <li class=md-nav__item> <a href=#numerical-simulation class=md-nav__link> <span class=md-ellipsis> Numerical Simulation </span> </a> <nav class=md-nav aria-label="Numerical Simulation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-architecture class=md-nav__link> <span class=md-ellipsis> Model Architecture </span> </a> </li> <li class=md-nav__item> <a href=#weights-and-biases class=md-nav__link> <span class=md-ellipsis> Weights and Biases </span> </a> </li> <li class=md-nav__item> <a href=#forward-pass class=md-nav__link> <span class=md-ellipsis> Forward Pass </span> </a> </li> <li class=md-nav__item> <a href=#loss-calculation class=md-nav__link> <span class=md-ellipsis> Loss Calculation </span> </a> </li> <li class=md-nav__item> <a href=#backward-pass class=md-nav__link> <span class=md-ellipsis> Backward Pass </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#additional class=md-nav__link> <span class=md-ellipsis> Additional </span> </a> <nav class=md-nav aria-label=Additional> <ul class=md-nav__list> <li class=md-nav__item> <a href=#relation-between-log-variance-and-standard-deviation class=md-nav__link> <span class=md-ellipsis> Relation between Log Variance and Standard Deviation </span> </a> <nav class=md-nav aria-label="Relation between Log Variance and Standard Deviation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-definitions class=md-nav__link> <span class=md-ellipsis> 1. Definitions </span> </a> </li> <li class=md-nav__item> <a href=#2-log-variance class=md-nav__link> <span class=md-ellipsis> 2. Log variance </span> </a> </li> <li class=md-nav__item> <a href=#3-relationship-between-log-variance-and-std class=md-nav__link> <span class=md-ellipsis> 3. Relationship between log variance and std </span> </a> </li> <li class=md-nav__item> <a href=#4-why-use-log-variance class=md-nav__link> <span class=md-ellipsis> 4. Why use log variance? </span> </a> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>14. VAE</h1> <h2 id=autoencoders>Autoencoders</h2> <p><strong>Autoencoders (AEs)</strong> are neural networks designed to learn efficient:</p> <ol> <li>codings of input data by compressing it into a lower-dimensional representation, and then;</li> <li>reconstructing it back to the original form.</li> </ol> <p>Autoencoders consist of two main components:</p> <ul> <li> <p><strong>an encoder</strong>, which compresses input data into a lower-dimensional representation known as the <strong>latent space</strong> or code. This latent space, often called embedding, aims to retain as much information as possible, allowing the decoder to reconstruct the data with high precision. If we denote our input data as <span class=arithmatex>\( x \)</span> and the encoder as <span class=arithmatex>\( E \)</span>, then the output latent space representation, <span class=arithmatex>\( s \)</span>, would be <span class=arithmatex>\( s=E(x) \)</span>.</p> </li> <li> <p><strong>a decoder</strong>, which reconstructs the original input data by accepting the latent space representation <span class=arithmatex>\( s \)</span>. If we denote the decoder function as <span class=arithmatex>\( D \)</span> and the output of the decoder as <span class=arithmatex>\( o \)</span>, then we can represent the decoder as <span class=arithmatex>\( o = D(s) \)</span>.</p> </li> </ul> <p>Both encoder and decoder are typically composed of one or more layers, which can be fully connected, convolutional, or recurrent, depending on the input data’s nature and the autoencoder’s architecture.<sup id=fnref:1><a class=footnote-ref href=#fn:1>1</a></sup> The entire autoencoder process can be summarized as:</p> <div class=arithmatex>\[ o = D(E(x)) \]</div> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=autoencoder-architecture.png><img alt="autoencoder architecture" src=autoencoder-architecture.png></a></p> <figcaption> <p>An illustration of the architecture of autoencoders. Source: <sup id=fnref2:1><a class=footnote-ref href=#fn:1>1</a></sup>.</p> </figcaption> </figure> <h2 id=types-of-autoencoder>Types of Autoencoder</h2> <p>There are several type of autoencoders, each one with this particularity:</p> <h3 id=vanilla-autoencoders><strong>Vanilla Autoencoders</strong></h3> <p>Vanilla encoders are fully connected layers for encoder and decoder. It works to compress input information and are applied over simple data.</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=vanilla-architecture.png><img alt="vanilla autoencoder" src=vanilla-architecture.png width=90%></a></p> <figcaption> <p>The encoder such as the decoder are fully connected networks. The encoder addresses the input data to the latent space (compressed space - encoded data). The decoder addresses the latent space data to output (reconstructed data). Source: <sup id=fnref3:1><a class=footnote-ref href=#fn:1>1</a></sup>.</p> </figcaption> </figure> <p>Latent Space is a compressed representation of the input data. The dimensionality of the latent space is typically much smaller than that of the input data, which forces the autoencoder to learn a compact representation that captures the most important features of the data.</p> <h3 id=convolutional-autoencoders><strong>Convolutional Autoencoders</strong></h3> <p>In convolutional autoencoders, the encoder and the decoder are neural networks based on Convolutional Neural Networks. So, the approach is more intensive for handling image data.</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=convolutional-architecture.png><img alt="convolutional autoencoder" src=convolutional-architecture.png></a></p> <figcaption> <p>In convolutional autoencoders, the encoder and decoder are based on Convolutional Neural Networks (CNNs). This architecture is particularly effective for image data, as it can capture spatial hierarchies and patterns. Source: <sup id=fnref:2><a class=footnote-ref href=#fn:2>2</a></sup>.</p> </figcaption> </figure> <h3 id=variational-autoencoders><strong>Variational Autoencoders</strong></h3> <p>Variational Autoencoders (VAEs) are generative models that learn to encode data into a lower-dimensional latent space and then decode it back to the original space. VAEs can generate new samples from the learned latent distribution, making them ideal for image generation and style transfer tasks.</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=variational-architecture.png><img alt="variational autoencoder" src=variational-architecture.png></a></p> <figcaption> <p>A VAE maps a input data <span class=arithmatex>\( \mathbf{x} \)</span> into latent space <span class=arithmatex>\( \mathbf{z} \)</span> and then reconstructs it back to the original space <span class=arithmatex>\( \mathbf{\hat{x}} \)</span> (output). The encoder learns to capture the underlying structure of the data, while the decoder generates new samples from the latent space. Source: <sup id=fnref2:2><a class=footnote-ref href=#fn:2>2</a></sup>.</p> </figcaption> </figure> <p>VAEs were introduced in <a href=https://arxiv.org/abs/1312.6114 target=_blank>2013 by Diederik et al. - Auto-Encoding Variational Bayes</a>.</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=autoencoder-vs-vae.png><img alt="autoencoder vs variational autoencoder" src=autoencoder-vs-vae.png width=70%></a></p> <figcaption> <p><em>Figure: Comparison between a standard Autoencoder and a Variational Autoencoder (VAE). In a standard Autoencoder, the encoder maps input data <span class=arithmatex>\( \mathbf{x} \)</span> to a fixed latent representation <span class=arithmatex>\( \mathbf{z} \)</span>, which is then used by the decoder to reconstruct the input as <span class=arithmatex>\( \mathbf{\hat{x}} \)</span>. In contrast, a VAE encodes the input data into a distribution over the latent space, typically modeled as a Gaussian distribution with mean <span class=arithmatex>\( \mu \)</span> and standard deviation <span class=arithmatex>\( \sigma \)</span>. During training, the VAE samples from this distribution to obtain <span class=arithmatex>\( \mathbf{z} \)</span>, which is then used by the decoder to reconstruct the input. This probabilistic approach allows VAEs to generate new samples by sampling from the latent space, making them powerful generative models. Dataset: <a href=https://github.com/zalandoresearch/fashion-mnist target=_blank>Fashion-MNIST</a>. Source: <sup id=fnref:3><a class=footnote-ref href=#fn:3>3</a></sup>.</em></p> </figcaption> </figure> <h4 id=key-features-of-vaes>Key Features of VAEs</h4> <p>VAEs have the ability to learn smooth and continuous latent spaces, which allows for meaningful interpolation between data points. This is particularly useful in applications such as image generation, where one can generate new images by sampling from the latent space. Also, the probabilistic nature of VAEs helps in regularizing the latent space, preventing overfitting and introducing the same level of randomness, ensuring that the model generalizes well to unseen data.</p> <p>Aspects of VAEs include:</p> <ul> <li> <p><strong>Regularization and Continuity</strong>: The latent space in VAEs is regularized to follow a prior distribution (usually a standard normal distribution). This encourages the model to learn a continuous and smooth latent space, allowing for meaningful interpolation between data points.</p> </li> <li> <p><strong>Simplicity in Sampling</strong>: VAEs can generate new samples by simply sampling from the latent space distribution - the Gaussian distribution is mathematically tractable and is a universal approximator -, making them efficient for generative tasks.</p> </li> <li> <p><strong>Reparameterization Trick</strong>: To enable backpropagation through the stochastic sampling process, VAEs employ the reparameterization trick. This involves expressing the sampled latent variable <span class=arithmatex>\( \mathbf{z} \)</span> as a deterministic function of the input data <span class=arithmatex>\( \mathbf{x} \)</span> and a random noise variable <span class=arithmatex>\( \mathbf{\epsilon} \)</span>, allowing gradients to flow through the network during training.</p> </li> <li> <p><strong>Balanced Latent Space</strong>: The KL divergence term in the VAE loss function encourages the learned latent space to be similar to the prior distribution, promoting a well-structured and balanced latent space.</p> </li> </ul> <h4 id=training-vaes>Training VAEs</h4> <p>VAEs uses Kullback-Leibler (KL) divergence as its loss function, which measures the difference between the learned latent distribution and the prior distribution. The loss function is a combination of the reconstruction loss (how well the decoder reconstructs the input) and the KL divergence term.</p> <p>Suppose we have a distribution <span class=arithmatex>\( z \)</span> and we want to approximate it with a distribution <span class=arithmatex>\( p(z|x) \)</span>, where <span class=arithmatex>\( x \)</span> is the input data. In other words, we want to find a distribution <span class=arithmatex>\( p(z|x) \)</span>, then we can to it by following Bayes' theorem:</p> <div class=arithmatex>\[ p(z|x) = \displaystyle \frac{p(x|z)p(z)}{p(x)} \]</div> <p>But, the problem is that <span class=arithmatex>\(p(x)\)</span> is intractable:</p> <div class=arithmatex>\[ p(x) = \displaystyle \int p(x|z)p(z)dz \]</div> <p>This integral is often intractable distribution. Hence, we can approximate it with a variational distribution <span class=arithmatex>\( q(z|x) \)</span>, which is easier to compute. So, we want to minimize the KL divergence between <span class=arithmatex>\( q(z|x) \)</span> and <span class=arithmatex>\( p(z|x) \)</span>:</p> <div class=arithmatex>\[ \min \text{KL} ( q(z|x) || (z|x) ) \]</div> <p>By simplifying the above minimization problem is equivalent to the following maximization problem:</p> <div class=arithmatex>\[ \mathbb{E}_{q(z|x)}[\log p(x|z)] - \text{KL}(q(z|x) || p(z)) \]</div> <p>where:</p> <ul> <li>The first term, <span class=arithmatex>\( \mathbb{E}_{q(z|x)}[\log p(x|z)] \)</span>, is the expected log-likelihood of the data given the latent variable, which encourages the model to reconstruct the input data accurately.</li> <li>The second term, <span class=arithmatex>\( \text{KL}(q(z|x) || p(z)) \)</span>, is the KL divergence between the approximate posterior and the prior distribution, which regularizes the latent space.</li> </ul> <p>Thus, the loss function for training a VAE can be expressed as:</p> <div class=arithmatex>\[ \mathcal{L} = -\mathbb{E}_{q(z|x)}[\log p(x|z)] + \text{KL}(q(z|x) || p(z)) \]</div> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=https://upload.wikimedia.org/wikipedia/commons/4/4a/VAE_Basic.png><img alt src=https://upload.wikimedia.org/wikipedia/commons/4/4a/VAE_Basic.png></a></p> <figcaption> <p><em>Figure: Basic architecture of a Variational Autoencoder (VAE). The encoder maps input data <span class=arithmatex>\( \mathbf{x} \)</span> to a latent representation <span class=arithmatex>\( \mathbf{z} \)</span>, and the decoder reconstructs <span class=arithmatex>\( \mathbf{x'} \)</span> from <span class=arithmatex>\( \mathbf{z} \)</span>. Source: <a href=https://en.wikipedia.org/wiki/Variational_autoencoder target=_blank>Wikipedia</a></em></p> </figcaption> </figure> <h4 id=reparameterization-trick>Reparameterization Trick</h4> <p>The reparameterization trick is a key innovation that allows for efficient backpropagation through the stochastic layers of a VAE. Instead of sampling <span class=arithmatex>\( z \)</span> directly from <span class=arithmatex>\( q(z|x) \)</span>, we can express <span class=arithmatex>\( z \)</span> as a deterministic function of <span class=arithmatex>\( x \)</span> and some noise <span class=arithmatex>\( \epsilon \)</span> drawn from a simple distribution (e.g., Gaussian):</p> <div class=arithmatex>\[ z = \mu + \sigma \cdot \epsilon \]</div> <p>where <span class=arithmatex>\( \mu \)</span> and <span class=arithmatex>\( \sigma \)</span> are the mean and standard deviation outputs of the encoder. This transformation allows us to backpropagate through the network while still maintaining the stochastic nature of the latent variable.</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=vae-reparametrized.png><img alt="reparametrized vae" src=vae-reparametrized.png></a></p> <hr> <h4 id=numerical-simulation>Numerical Simulation</h4> <details class=example open=open> <summary>VAE - Variational Autoencoder</summary> <p>A Variational Autoencoder (VAE) encodes input data into a probabilistic latent space (defined by mean μ and log-variance log(σ²)) and decodes it back to reconstruct the input. The latent space is sampled using the reparameterization trick for differentiability. The loss combines reconstruction error (MSE) and KL divergence to regularize the latent distribution toward a standard normal.</p> <p>For this numerical example, we've scaled up to:</p> <ul> <li>Input dimension: 4 (e.g., a vector like <code>[1.0, 2.0, 3.0, 4.0]</code>)</li> <li>Latent dimension: 2</li> <li>Output dimension: 4 (reconstruction of input)</li> <li>Hidden layer size: 8 (for both encoder and decoder, to add capacity)</li> </ul> <p>The model uses PyTorch with random initialization (seeded at 42 for reproducibility). All calculations are shown step-by-step, including matrix multiplications where relevant. Weights and biases are explicitly listed below.</p> <h5 id=model-architecture>Model Architecture</h5> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=vae-4-8-2-8-4.png><img alt src=vae-4-8-2-8-4.png></a></p> <ul> <li> <p><strong>Encoder</strong>:</p> <ul> <li>Linear (fc1): 4 inputs → 8 hidden units, followed by ReLU.</li> <li>Linear to μ (fc_mu): 8 → 2.</li> <li>Linear to logvar (fc_logvar): 8 → 2.</li> </ul> </li> <li> <p><strong>Latent</strong>: Sample z from N(μ, σ²) using reparameterization trick.</p> </li> <li> <p><strong>Decoder</strong>:</p> <ul> <li>Linear (fc_dec1): 2 latent → 8 hidden units, followed by ReLU.</li> <li>Linear to output (fc_dec2): 8 → 4 (no final activation, assuming Gaussian output for simplicity).</li> </ul> </li> <li> <p><strong>Loss</strong>: Summed MSE for reconstruction + KL divergence (without β annealing).</p> </li> </ul> <h5 id=weights-and-biases>Weights and Biases</h5> <p>All parameters are initialized randomly (via torch.manual_seed(42)). Here they are:</p> <hr> <p><strong>Encoder</strong></p> <ul> <li> <p><strong>fc1.weight</strong> (encoder input to hidden, shape [8, 4]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a href=#__codelineno-0-1 id=__codelineno-0-1 name=__codelineno-0-1></a><span class=p>[</span>
</span><span id=__span-0-2><a href=#__codelineno-0-2 id=__codelineno-0-2 name=__codelineno-0-2></a>    <span class=p>[</span> <span class=mf>0.3823</span><span class=p>,</span>  <span class=mf>0.4150</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1171</span><span class=p>,</span>  <span class=mf>0.4593</span><span class=p>],</span>
</span><span id=__span-0-3><a href=#__codelineno-0-3 id=__codelineno-0-3 name=__codelineno-0-3></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.1096</span><span class=p>,</span>  <span class=mf>0.1009</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2434</span><span class=p>,</span>  <span class=mf>0.2936</span><span class=p>],</span>
</span><span id=__span-0-4><a href=#__codelineno-0-4 id=__codelineno-0-4 name=__codelineno-0-4></a>    <span class=p>[</span> <span class=mf>0.4408</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3668</span><span class=p>,</span>  <span class=mf>0.4346</span><span class=p>,</span>  <span class=mf>0.0936</span><span class=p>],</span>
</span><span id=__span-0-5><a href=#__codelineno-0-5 id=__codelineno-0-5 name=__codelineno-0-5></a>    <span class=p>[</span> <span class=mf>0.3694</span><span class=p>,</span>  <span class=mf>0.0677</span><span class=p>,</span>  <span class=mf>0.2411</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0706</span><span class=p>],</span>
</span><span id=__span-0-6><a href=#__codelineno-0-6 id=__codelineno-0-6 name=__codelineno-0-6></a>    <span class=p>[</span> <span class=mf>0.3854</span><span class=p>,</span>  <span class=mf>0.0739</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2334</span><span class=p>,</span>  <span class=mf>0.1274</span><span class=p>],</span>
</span><span id=__span-0-7><a href=#__codelineno-0-7 id=__codelineno-0-7 name=__codelineno-0-7></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.2304</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0586</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2031</span><span class=p>,</span>  <span class=mf>0.3317</span><span class=p>],</span>
</span><span id=__span-0-8><a href=#__codelineno-0-8 id=__codelineno-0-8 name=__codelineno-0-8></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.3947</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2305</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1412</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3006</span><span class=p>],</span>
</span><span id=__span-0-9><a href=#__codelineno-0-9 id=__codelineno-0-9 name=__codelineno-0-9></a>    <span class=p>[</span> <span class=mf>0.0472</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.4938</span><span class=p>,</span>  <span class=mf>0.4516</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.4247</span><span class=p>]</span>
</span><span id=__span-0-10><a href=#__codelineno-0-10 id=__codelineno-0-10 name=__codelineno-0-10></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc1.bias</strong> (shape [8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a href=#__codelineno-1-1 id=__codelineno-1-1 name=__codelineno-1-1></a><span class=p>[</span> <span class=mf>0.3860</span><span class=p>,</span>  <span class=mf>0.0832</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1624</span><span class=p>,</span>  <span class=mf>0.3090</span><span class=p>,</span>  <span class=mf>0.0779</span><span class=p>,</span>  <span class=mf>0.4040</span><span class=p>,</span>  <span class=mf>0.0547</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1577</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_mu.weight</strong> (hidden to μ, shape [2, 8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a href=#__codelineno-2-1 id=__codelineno-2-1 name=__codelineno-2-1></a><span class=p>[</span>
</span><span id=__span-2-2><a href=#__codelineno-2-2 id=__codelineno-2-2 name=__codelineno-2-2></a>    <span class=p>[</span> <span class=mf>0.0950</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0959</span><span class=p>,</span>  <span class=mf>0.1488</span><span class=p>,</span>  <span class=mf>0.3157</span><span class=p>,</span>  <span class=mf>0.2044</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1546</span><span class=p>,</span>  <span class=mf>0.2041</span><span class=p>,</span>  <span class=mf>0.0633</span><span class=p>],</span>
</span><span id=__span-2-3><a href=#__codelineno-2-3 id=__codelineno-2-3 name=__codelineno-2-3></a>    <span class=p>[</span> <span class=mf>0.1795</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2155</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3500</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1366</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2712</span><span class=p>,</span>  <span class=mf>0.2901</span><span class=p>,</span>  <span class=mf>0.1018</span><span class=p>,</span>  <span class=mf>0.1464</span><span class=p>]</span>
</span><span id=__span-2-4><a href=#__codelineno-2-4 id=__codelineno-2-4 name=__codelineno-2-4></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_mu.bias</strong> (shape [2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a href=#__codelineno-3-1 id=__codelineno-3-1 name=__codelineno-3-1></a><span class=p>[</span> <span class=mf>0.1118</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0062</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_logvar.weight</strong> (hidden to logvar, shape [2, 8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a href=#__codelineno-4-1 id=__codelineno-4-1 name=__codelineno-4-1></a><span class=p>[</span>
</span><span id=__span-4-2><a href=#__codelineno-4-2 id=__codelineno-4-2 name=__codelineno-4-2></a>    <span class=p>[</span> <span class=mf>0.2767</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2512</span><span class=p>,</span>  <span class=mf>0.0223</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2413</span><span class=p>,</span>  <span class=mf>0.1090</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1218</span><span class=p>,</span>  <span class=mf>0.1083</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0737</span><span class=p>],</span>
</span><span id=__span-4-3><a href=#__codelineno-4-3 id=__codelineno-4-3 name=__codelineno-4-3></a>    <span class=p>[</span> <span class=mf>0.2932</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2096</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2109</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2109</span><span class=p>,</span>  <span class=mf>0.3180</span><span class=p>,</span>  <span class=mf>0.1178</span><span class=p>,</span>  <span class=mf>0.3402</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2918</span><span class=p>]</span>
</span><span id=__span-4-4><a href=#__codelineno-4-4 id=__codelineno-4-4 name=__codelineno-4-4></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_logvar.bias</strong> (shape [2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a href=#__codelineno-5-1 id=__codelineno-5-1 name=__codelineno-5-1></a><span class=p>[</span> <span class=o>-</span><span class=mf>0.3507</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2766</span> <span class=p>]</span>
</span></code></pre></div> </li> </ul> <hr> <p><strong>Decoder</strong></p> <ul> <li> <p><strong>fc_dec1.weight</strong> (latent to decoder hidden, shape [8, 2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a href=#__codelineno-6-1 id=__codelineno-6-1 name=__codelineno-6-1></a><span class=p>[</span>
</span><span id=__span-6-2><a href=#__codelineno-6-2 id=__codelineno-6-2 name=__codelineno-6-2></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.4757</span><span class=p>,</span>  <span class=mf>0.2864</span><span class=p>],</span>
</span><span id=__span-6-3><a href=#__codelineno-6-3 id=__codelineno-6-3 name=__codelineno-6-3></a>    <span class=p>[</span> <span class=mf>0.2532</span><span class=p>,</span>  <span class=mf>0.5876</span><span class=p>],</span>
</span><span id=__span-6-4><a href=#__codelineno-6-4 id=__codelineno-6-4 name=__codelineno-6-4></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.3652</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.4820</span><span class=p>],</span>
</span><span id=__span-6-5><a href=#__codelineno-6-5 id=__codelineno-6-5 name=__codelineno-6-5></a>    <span class=p>[</span> <span class=mf>0.3752</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2858</span><span class=p>],</span>
</span><span id=__span-6-6><a href=#__codelineno-6-6 id=__codelineno-6-6 name=__codelineno-6-6></a>    <span class=p>[</span> <span class=mf>0.4292</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1678</span><span class=p>],</span>
</span><span id=__span-6-7><a href=#__codelineno-6-7 id=__codelineno-6-7 name=__codelineno-6-7></a>    <span class=p>[</span> <span class=mf>0.4045</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5494</span><span class=p>],</span>
</span><span id=__span-6-8><a href=#__codelineno-6-8 id=__codelineno-6-8 name=__codelineno-6-8></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.3568</span><span class=p>,</span>  <span class=mf>0.2156</span><span class=p>],</span>
</span><span id=__span-6-9><a href=#__codelineno-6-9 id=__codelineno-6-9 name=__codelineno-6-9></a>    <span class=p>[</span> <span class=mf>0.1495</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1803</span><span class=p>]</span>
</span><span id=__span-6-10><a href=#__codelineno-6-10 id=__codelineno-6-10 name=__codelineno-6-10></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_dec1.bias</strong> (shape [8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a href=#__codelineno-7-1 id=__codelineno-7-1 name=__codelineno-7-1></a><span class=p>[</span> <span class=mf>0.4215</span><span class=p>,</span>  <span class=mf>0.4807</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5128</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3775</span><span class=p>,</span>  <span class=mf>0.6475</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2386</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2507</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.6842</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_dec2.weight</strong> (decoder hidden to output, shape [4, 8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a href=#__codelineno-8-1 id=__codelineno-8-1 name=__codelineno-8-1></a><span class=p>[</span>
</span><span id=__span-8-2><a href=#__codelineno-8-2 id=__codelineno-8-2 name=__codelineno-8-2></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.2025</span><span class=p>,</span>  <span class=mf>0.0883</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0467</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2566</span><span class=p>,</span>  <span class=mf>0.0083</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2415</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1947</span><span class=p>],</span>
</span><span id=__span-8-3><a href=#__codelineno-8-3 id=__codelineno-8-3 name=__codelineno-8-3></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.3094</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2251</span><span class=p>,</span>  <span class=mf>0.3534</span><span class=p>,</span>  <span class=mf>0.0668</span><span class=p>,</span>  <span class=mf>0.1090</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3298</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2322</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1177</span><span class=p>],</span>
</span><span id=__span-8-4><a href=#__codelineno-8-4 id=__codelineno-8-4 name=__codelineno-8-4></a>    <span class=p>[</span> <span class=mf>0.0553</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3111</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1523</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2117</span><span class=p>,</span>  <span class=mf>0.0010</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1316</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0245</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2396</span><span class=p>],</span>
</span><span id=__span-8-5><a href=#__codelineno-8-5 id=__codelineno-8-5 name=__codelineno-8-5></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.2427</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2063</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1210</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2791</span><span class=p>,</span>  <span class=mf>0.2964</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0702</span><span class=p>,</span>  <span class=mf>0.3042</span><span class=p>,</span>  <span class=mf>0.1102</span><span class=p>]</span>
</span><span id=__span-8-6><a href=#__codelineno-8-6 id=__codelineno-8-6 name=__codelineno-8-6></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_dec2.bias</strong> (shape [4]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a href=#__codelineno-9-1 id=__codelineno-9-1 name=__codelineno-9-1></a><span class=p>[</span> <span class=o>-</span><span class=mf>0.2994</span><span class=p>,</span>  <span class=mf>0.2447</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0973</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1355</span> <span class=p>]</span>
</span></code></pre></div> </li> </ul> <h5 id=forward-pass>Forward Pass</h5> <ol> <li> <p><strong>Input</strong>:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a href=#__codelineno-10-1 id=__codelineno-10-1 name=__codelineno-10-1></a><span class=n>x</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>,</span> <span class=mf>4.0</span> <span class=p>]</span>
</span></code></pre></div> <p>(batch size 1, dim 4).</p> </li> <li> <p><strong>Encoding to Hidden Layer</strong>:</p> <ul> <li> <p>Compute pre-ReLU: fc1(x) = fc1.weight @ x^T + fc1.bias.</p> <ul> <li>This is a matrix multiplication: Each row of fc1.weight dotted with x, plus bias.</li> <li>Result (pre-ReLU): <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a href=#__codelineno-11-1 id=__codelineno-11-1 name=__codelineno-11-1></a><span class=p>[</span> <span class=mf>3.0842</span><span class=p>,</span>  <span class=mf>0.6196</span><span class=p>,</span>  <span class=mf>1.223</span><span class=p>,</span>   <span class=mf>1.2547</span><span class=p>,</span>  <span class=mf>0.4205</span><span class=p>,</span>  <span class=mf>0.7739</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.427</span><span class=p>,</span>  <span class=o>-</span><span class=mf>1.4421</span> <span class=p>]</span>
</span></code></pre></div></li> <li>After ReLU (non-negative): <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a href=#__codelineno-12-1 id=__codelineno-12-1 name=__codelineno-12-1></a><span class=n>encoder_8</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>3.0842</span><span class=p>,</span> <span class=mf>0.6196</span><span class=p>,</span> <span class=mf>1.223</span><span class=p>,</span>  <span class=mf>1.2547</span><span class=p>,</span> <span class=mf>0.4205</span><span class=p>,</span> <span class=mf>0.7739</span><span class=p>,</span> <span class=mf>0.</span><span class=p>,</span> <span class=mf>0.</span> <span class=p>]</span>
</span></code></pre></div> (note: last two are zeroed by ReLU).</li> </ul> </li> </ul> </li> <li> <p><strong>Compute Mean (μ) in Latent Space</strong>:</p> <ul> <li>μ = fc_mu.weight @ hidden^T + fc_mu.bias.<ul> <li>Result: <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a href=#__codelineno-13-1 id=__codelineno-13-1 name=__codelineno-13-1></a><span class=n>μ</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>0.88977581</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.07508313</span> <span class=p>]</span>
</span></code></pre></div></li> <li>This is the mean of the 2D latent Gaussian.</li> </ul> </li> </ul> </li> <li> <p><strong>Compute Log-Variance (logvar) in Latent Space</strong>:</p> <ul> <li> <p>logvar = fc_logvar.weight @ hidden^T + fc_logvar.bias.</p> <ul> <li>Result: <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a href=#__codelineno-14-1 id=__codelineno-14-1 name=__codelineno-14-1></a><span class=n>logvar</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>0.02314189</span><span class=p>,</span> <span class=mf>0.20015677</span> <span class=p>]</span>
</span></code></pre></div></li> <li>Variance σ² = exp(logvar): <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a href=#__codelineno-15-1 id=__codelineno-15-1 name=__codelineno-15-1></a><span class=n>variance</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>1.02341174</span><span class=p>,</span> <span class=mf>1.22159425</span> <span class=p>]</span>
</span></code></pre></div></li> </ul> </li> </ul> </li> <li> <p><strong>Latent Space: Sampling z (Reparameterization Trick)</strong>:</p> <ul> <li> <p>std (σ) = exp(0.5 * logvar): </p><div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a href=#__codelineno-16-1 id=__codelineno-16-1 name=__codelineno-16-1></a><span class=n>std</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>1.01163815</span><span class=p>,</span> <span class=mf>1.10525755</span> <span class=p>]</span>
</span></code></pre></div><p></p> </li> <li> <p>ε ~ N(0, 1) (seeded random): </p><div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a href=#__codelineno-17-1 id=__codelineno-17-1 name=__codelineno-17-1></a><span class=n>ε</span> <span class=o>=</span> <span class=p>[</span> <span class=o>-</span><span class=mf>0.2387</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5050</span> <span class=p>]</span>
</span></code></pre></div><p></p> </li> <li> <p><span class=arithmatex>\( z = \mu + std * \epsilon \)</span></p> </li> <li> <p>Result: </p><div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a href=#__codelineno-18-1 id=__codelineno-18-1 name=__codelineno-18-1></a><span class=n>z</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>0.88977581</span> <span class=o>+</span> <span class=mf>1.01163815</span><span class=o>*</span><span class=p>(</span><span class=o>-</span><span class=mf>0.2387</span><span class=p>),</span> <span class=o>-</span><span class=mf>0.07508313</span> <span class=o>+</span> <span class=mf>1.10525755</span><span class=o>*</span><span class=p>(</span><span class=o>-</span><span class=mf>0.5050</span><span class=p>)</span> <span class=p>]</span> 
</span><span id=__span-18-2><a href=#__codelineno-18-2 id=__codelineno-18-2 name=__codelineno-18-2></a>    <span class=err>≈</span> <span class=p>[</span> <span class=mf>0.64829778</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.63323819</span> <span class=p>]</span>
</span></code></pre></div><p></p> </li> </ul> </li> <li> <p><strong>Decoding to Reconstructed Output</strong>:</p> <ul> <li>Decoder: ReLu( fc_dec1.weight @ z^T + fc_dec1.bias ).<ul> <li>pre-ReLU: <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a href=#__codelineno-19-1 id=__codelineno-19-1 name=__codelineno-19-1></a><span class=n>decoder_hidden</span> <span class=o>=</span> <span class=p>[</span> <span class=o>-</span><span class=mf>0.06825467</span><span class=p>,</span>  <span class=mf>0.27275824</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.44433754</span><span class=p>,</span>  <span class=mf>0.0467208</span><span class=p>,</span>   <span class=mf>1.03200678</span><span class=p>,</span>  <span class=mf>0.37153752</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.6185388</span><span class=p>,</span>  <span class=o>-</span><span class=mf>0.47310664</span> <span class=p>]</span>
</span></code></pre></div></li> <li>After ReLU: <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a href=#__codelineno-20-1 id=__codelineno-20-1 name=__codelineno-20-1></a><span class=n>decoder_hidden</span> <span class=o>=</span> <span class=p>[</span> <span class=mf>0.</span><span class=p>,</span> <span class=mf>0.27275824</span><span class=p>,</span> <span class=mf>0.</span><span class=p>,</span> <span class=mf>0.0467208</span><span class=p>,</span>  <span class=mf>1.03200678</span><span class=p>,</span> <span class=mf>0.37153752</span><span class=p>,</span> <span class=mf>0.</span><span class=p>,</span> <span class=mf>0.</span> <span class=p>]</span>
</span></code></pre></div></li> </ul> </li> <li> <p>recon_x = fc_dec2.weight @ decoder_hidden^T + fc_dec2.bias.</p> <ul> <li> <p>Result:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a href=#__codelineno-21-1 id=__codelineno-21-1 name=__codelineno-21-1></a><span class=n>recon_x</span> <span class=o>=</span> <span class=p>[</span> <span class=o>-</span><span class=mf>0.36846466</span><span class=p>,</span>  <span class=mf>0.17637874</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.23990821</span><span class=p>,</span>  <span class=mf>0.07499507</span> <span class=p>]</span>
</span></code></pre></div> </li> </ul> </li> </ul> </li> </ol> <h5 id=loss-calculation>Loss Calculation</h5> <ul> <li> <p><strong>Reconstruction Loss (MSE)</strong>:</p> <p>Sum over dimensions of <span class=arithmatex>\( (x - \hat{x})^2 ≈ 31.100958927489703 \)</span></p> </li> <li> <p><strong>KL Divergence</strong>:</p> <div class=arithmatex>\[ \text{KL} = -0.5 * \sum \left(1 + \text{logvar} - \mu^2 - \exp(\text{logvar})\right) \approx 0.40952290104490313 \]</div> </li> <li> <p><strong>Total Loss</strong>:</p> <div class=arithmatex>\[ \text{Loss} = \text{MSE} + \text{KL} \approx 31.510481828534605 \]</div> </li> </ul> <h5 id=backward-pass>Backward Pass</h5> <p>The backward pass computes gradients via autograd (chain rule from loss back through the network). This enables training by updating weights (e.g., via SGD). Gradients are zero-initialized before .backward().</p> <p>After loss.backward(), key gradients <span class=arithmatex>\( \displaystyle \frac{\partial \text{Loss}}{\partial \text{param}} \)</span> are:</p> <hr> <p><strong>Decoder</strong></p> <ul> <li> <p><strong>fc_dec2.weight.grad</strong> (shape [4, 8]):</p> <div class=arithmatex>\[ \displaystyle \frac{\partial \text{L}}{\partial \text{fc_dec2.weight}} \]</div> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a href=#__codelineno-22-1 id=__codelineno-22-1 name=__codelineno-22-1></a><span class=p>[</span>
</span><span id=__span-22-2><a href=#__codelineno-22-2 id=__codelineno-22-2 name=__codelineno-22-2></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.7467</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1278</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.8242</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.0167</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-22-3><a href=#__codelineno-22-3 id=__codelineno-22-3 name=__codelineno-22-3></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.9951</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1703</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.7638</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.3549</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-22-4><a href=#__codelineno-22-4 id=__codelineno-22-4 name=__codelineno-22-4></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.7679</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3025</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.6867</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.4071</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-22-5><a href=#__codelineno-22-5 id=__codelineno-22-5 name=__codelineno-22-5></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.1417</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3664</span><span class=p>,</span> <span class=o>-</span><span class=mf>8.1006</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.9161</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>]</span>
</span><span id=__span-22-6><a href=#__codelineno-22-6 id=__codelineno-22-6 name=__codelineno-22-6></a><span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_dec2.bias.grad</strong> (shape [4]): </p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a href=#__codelineno-23-1 id=__codelineno-23-1 name=__codelineno-23-1></a><span class=p>[</span> <span class=o>-</span><span class=mf>2.7369</span><span class=p>,</span> <span class=o>-</span><span class=mf>3.6474</span><span class=p>,</span> <span class=o>-</span><span class=mf>6.4798</span><span class=p>,</span> <span class=o>-</span><span class=mf>7.8500</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_dec1.weight.grad</strong> (shape [8, 2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a href=#__codelineno-24-1 id=__codelineno-24-1 name=__codelineno-24-1></a><span class=p>[</span>
</span><span id=__span-24-2><a href=#__codelineno-24-2 id=__codelineno-24-2 name=__codelineno-24-2></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-24-3><a href=#__codelineno-24-3 id=__codelineno-24-3 name=__codelineno-24-3></a>    <span class=p>[</span> <span class=mf>2.7321</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.6684</span><span class=p>],</span>
</span><span id=__span-24-4><a href=#__codelineno-24-4 id=__codelineno-24-4 name=__codelineno-24-4></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-24-5><a href=#__codelineno-24-5 id=__codelineno-24-5 name=__codelineno-24-5></a>    <span class=p>[</span> <span class=mf>2.6066</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.5459</span><span class=p>],</span>
</span><span id=__span-24-6><a href=#__codelineno-24-6 id=__codelineno-24-6 name=__codelineno-24-6></a>    <span class=p>[</span><span class=o>-</span><span class=mf>1.7850</span><span class=p>,</span>  <span class=mf>1.7434</span><span class=p>],</span>
</span><span id=__span-24-7><a href=#__codelineno-24-7 id=__codelineno-24-7 name=__codelineno-24-7></a>    <span class=p>[</span> <span class=mf>2.1179</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.0685</span><span class=p>],</span>
</span><span id=__span-24-8><a href=#__codelineno-24-8 id=__codelineno-24-8 name=__codelineno-24-8></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-24-9><a href=#__codelineno-24-9 id=__codelineno-24-9 name=__codelineno-24-9></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>]</span>
</span><span id=__span-24-10><a href=#__codelineno-24-10 id=__codelineno-24-10 name=__codelineno-24-10></a><span class=p>]</span>
</span></code></pre></div> <ul> <li>Primarily from MSE, backpropagated through decoder.</li> </ul> </li> <li> <p><strong>fc_dec1.bias.grad</strong> (shape [8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a href=#__codelineno-25-1 id=__codelineno-25-1 name=__codelineno-25-1></a><span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>4.2144</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>4.0209</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.7535</span><span class=p>,</span>  <span class=mf>3.2670</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span> <span class=p>]</span>
</span></code></pre></div> </li> </ul> <hr> <p><strong>Encoder</strong></p> <ul> <li> <p><strong>fc_mu.weight.grad</strong> (shape [2, 8]):</p> <p></p><div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a href=#__codelineno-26-1 id=__codelineno-26-1 name=__codelineno-26-1></a><span class=p>[</span>
</span><span id=__span-26-2><a href=#__codelineno-26-2 id=__codelineno-26-2 name=__codelineno-26-2></a>    <span class=p>[</span><span class=mf>11.1188</span><span class=p>,</span>  <span class=mf>2.2342</span><span class=p>,</span>  <span class=mf>4.4088</span><span class=p>,</span>  <span class=mf>4.5235</span><span class=p>,</span>  <span class=mf>1.5168</span><span class=p>,</span>  <span class=mf>2.7899</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-26-3><a href=#__codelineno-26-3 id=__codelineno-26-3 name=__codelineno-26-3></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.2493</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0501</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0989</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1014</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0340</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0626</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>]</span>
</span><span id=__span-26-4><a href=#__codelineno-26-4 id=__codelineno-26-4 name=__codelineno-26-4></a><span class=p>]</span>
</span></code></pre></div> - Includes ∂KL/∂μ ≈ μ (pulling toward 0) + flow from MSE via z.<p></p> </li> <li> <p><strong>fc_mu.bias.grad</strong> (shape [2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a href=#__codelineno-27-1 id=__codelineno-27-1 name=__codelineno-27-1></a><span class=p>[</span> <span class=mf>3.6052</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0808</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc_logvar.weight.grad</strong> (shape [2, 8]):</p> <p></p><div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a href=#__codelineno-28-1 id=__codelineno-28-1 name=__codelineno-28-1></a><span class=p>[</span>
</span><span id=__span-28-2><a href=#__codelineno-28-2 id=__codelineno-28-2 name=__codelineno-28-2></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.9752</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1960</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3867</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.3967</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.1330</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2447</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-28-3><a href=#__codelineno-28-3 id=__codelineno-28-3 name=__codelineno-28-3></a>    <span class=p>[</span> <span class=mf>0.3473</span><span class=p>,</span>  <span class=mf>0.0698</span><span class=p>,</span>  <span class=mf>0.1377</span><span class=p>,</span>  <span class=mf>0.1413</span><span class=p>,</span>  <span class=mf>0.0474</span><span class=p>,</span>  <span class=mf>0.0871</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>]</span>
</span><span id=__span-28-4><a href=#__codelineno-28-4 id=__codelineno-28-4 name=__codelineno-28-4></a><span class=p>]</span>
</span></code></pre></div> - From ∂KL/∂logvar ≈ 0.5*(exp(logvar) - 1) + MSE flow.<p></p> </li> <li> <p><strong>fc_logvar.bias.grad</strong> (shape [2]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a href=#__codelineno-29-1 id=__codelineno-29-1 name=__codelineno-29-1></a><span class=p>[</span> <span class=o>-</span><span class=mf>0.3162</span><span class=p>,</span>  <span class=mf>0.1126</span> <span class=p>]</span>
</span></code></pre></div> </li> <li> <p><strong>fc1.weight.grad</strong> (shape [8, 4]): </p><div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a href=#__codelineno-30-1 id=__codelineno-30-1 name=__codelineno-30-1></a><span class=p>[</span>
</span><span id=__span-30-2><a href=#__codelineno-30-2 id=__codelineno-30-2 name=__codelineno-30-2></a>    <span class=p>[</span> <span class=mf>0.2735</span><span class=p>,</span>  <span class=mf>0.5470</span><span class=p>,</span>  <span class=mf>0.8204</span><span class=p>,</span>  <span class=mf>1.0939</span><span class=p>],</span>
</span><span id=__span-30-3><a href=#__codelineno-30-3 id=__codelineno-30-3 name=__codelineno-30-3></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.2724</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5448</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.8172</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.0896</span><span class=p>],</span>
</span><span id=__span-30-4><a href=#__codelineno-30-4 id=__codelineno-30-4 name=__codelineno-30-4></a>    <span class=p>[</span> <span class=mf>0.5339</span><span class=p>,</span>  <span class=mf>1.0679</span><span class=p>,</span>  <span class=mf>1.6018</span><span class=p>,</span>  <span class=mf>2.1358</span><span class=p>],</span>
</span><span id=__span-30-5><a href=#__codelineno-30-5 id=__codelineno-30-5 name=__codelineno-30-5></a>    <span class=p>[</span> <span class=mf>1.2016</span><span class=p>,</span>  <span class=mf>2.4032</span><span class=p>,</span>  <span class=mf>3.6049</span><span class=p>,</span>  <span class=mf>4.8065</span><span class=p>],</span>
</span><span id=__span-30-6><a href=#__codelineno-30-6 id=__codelineno-30-6 name=__codelineno-30-6></a>    <span class=p>[</span> <span class=mf>0.7601</span><span class=p>,</span>  <span class=mf>1.5201</span><span class=p>,</span>  <span class=mf>2.2802</span><span class=p>,</span>  <span class=mf>3.0403</span><span class=p>],</span>
</span><span id=__span-30-7><a href=#__codelineno-30-7 id=__codelineno-30-7 name=__codelineno-30-7></a>    <span class=p>[</span><span class=o>-</span><span class=mf>0.5289</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.0578</span><span class=p>,</span> <span class=o>-</span><span class=mf>1.5868</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.1157</span><span class=p>],</span>
</span><span id=__span-30-8><a href=#__codelineno-30-8 id=__codelineno-30-8 name=__codelineno-30-8></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>],</span>
</span><span id=__span-30-9><a href=#__codelineno-30-9 id=__codelineno-30-9 name=__codelineno-30-9></a>    <span class=p>[</span> <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>]</span>
</span><span id=__span-30-10><a href=#__codelineno-30-10 id=__codelineno-30-10 name=__codelineno-30-10></a><span class=p>]</span>
</span></code></pre></div><p></p> <ul> <li>These flow from both MSE (via reconstruction) and KL (via μ/logvar). Zeros in last rows due to ReLU zeroing those hidden units.</li> </ul> </li> <li> <p><strong>fc1.bias.grad</strong> (shape [8]):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-31-1><a href=#__codelineno-31-1 id=__codelineno-31-1 name=__codelineno-31-1></a><span class=p>[</span> <span class=mf>0.2735</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.2724</span><span class=p>,</span>  <span class=mf>0.5339</span><span class=p>,</span>  <span class=mf>1.2016</span><span class=p>,</span>  <span class=mf>0.7601</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5289</span><span class=p>,</span>  <span class=mf>0.0000</span><span class=p>,</span>  <span class=mf>0.0000</span> <span class=p>]</span>
</span></code></pre></div> </li> </ul> <p>These gradients would update parameters in training (e.g., param -= lr * grad). Note zeros where ReLU gates flow. This example uses a single pass; real training iterates over datasets. If you change the seed, input, or dimensions, values will differ, but the process remains identical.</p> </details> <hr> <h2 id=additional>Additional</h2> <h3 id=relation-between-log-variance-and-standard-deviation>Relation between Log Variance and Standard Deviation</h3> <details class=tip open=open> <summary>Relation between Log Variance and Standard Deviation</summary> <ul> <li>In VAEs, the encoder outputs the mean <span class=arithmatex>\( \mu \)</span> and log variance <span class=arithmatex>\( \log(\sigma^2) \)</span> of the latent space distribution.</li> <li>The standard deviation <span class=arithmatex>\( \sigma \)</span> can be derived from the log variance using the relationship:</li> </ul> <div class=arithmatex>\[ \sigma = \exp\left(\frac{1}{2} \log(\sigma^2)\right) \]</div> <ul> <li>This transformation ensures numerical stability and positivity of the variance during training.</li> </ul> <hr> <h4 id=1-definitions>1. Definitions</h4> <p>For a random variable ( x ) that follows a normal distribution:</p> <div class=arithmatex>\[ x \sim \mathcal{N}(\mu, \sigma^2) \]</div> <p>where:</p> <ul> <li><span class=arithmatex>\( \mu \)</span>: mean</li> <li><span class=arithmatex>\( \sigma^2 \)</span>: variance</li> <li><span class=arithmatex>\( \sigma \)</span>: standard deviation</li> </ul> <hr> <h4 id=2-log-variance>2. Log variance</h4> <p>Often, instead of directly predicting or storing the variance <span class=arithmatex>\( \sigma^2 \)</span> or standard deviation <span class=arithmatex>\( \sigma \)</span>, models work with the <strong>log variance</strong>:</p> <div class=arithmatex>\[ \displaystyle \text{log_var} = \log(\sigma^2) \]</div> <hr> <h4 id=3-relationship-between-log-variance-and-std>3. Relationship between log variance and std</h4> <p>From the above definition:</p> <div class=arithmatex>\[ \displaystyle \sigma^2 = e^{\text{log_var}} \]</div> <p>Taking the square root to get the standard deviation:</p> <div class=arithmatex>\[ \displaystyle \sigma = \displaystyle \sqrt{e^{\text{log_var}}} = \displaystyle e^{\frac{1}{2}\text{log_var}} \]</div> <p><strong>So:</strong></p> <div class=arithmatex>\[ \displaystyle \boxed{\sigma = \exp\left(\frac{1}{2} \cdot \text{log_var}\right)} \]</div> <p>and conversely,</p> <div class=arithmatex>\[ \displaystyle \boxed{\text{log_var} = 2 \cdot \log(\sigma)} \]</div> <hr> <h4 id=4-why-use-log-variance>4. Why use log variance?</h4> <p>It’s common in neural nets because:</p> <ul> <li>It ensures the variance is always <strong>positive</strong> (since <span class=arithmatex>\( e^x &gt; 0 \)</span>).</li> <li>It’s numerically <strong>more stable</strong> when optimizing.</li> <li>It allows unconstrained outputs from the network (no need to force positivity).</li> </ul> <hr> <h4 id=summary>Summary</h4> <table> <thead> <tr> <th>Quantity</th> <th>Expression</th> <th>In terms of log_var</th> </tr> </thead> <tbody> <tr> <td>Variance</td> <td><span class=arithmatex>\( \sigma^2 \)</span></td> <td><span class=arithmatex>\( e^{\text{log_var}} \)</span></td> </tr> <tr> <td>Std. deviation</td> <td><span class=arithmatex>\( \sigma \)</span></td> <td><span class=arithmatex>\( e^{\frac{1}{2}\text{log_var}} \)</span></td> </tr> <tr> <td>Log variance</td> <td><span class=arithmatex>\( \text{log_var} \)</span></td> <td><span class=arithmatex>\( 2 \log(\sigma) \)</span></td> </tr> </tbody> </table> </details> <!-- ![reparameterization trick](vae-reparametrization-trick.png)

##### Fashion-MNIST

??? example "Fashion-MNIST"

    Below is a basic example of how to create and train a VAE on the Fashion-MNIST dataset.


    <!-- ??? info "Architecture Visualization"

        === "Encoder"

            ![](vae_example_fashion_mnist_files/encoder_network.png)

        === "Decoder"

            ![](vae_example_fashion_mnist_files/decoder_network.png) --> <div class=footnote> <hr> <ol> <li id=fn:1> <p><a href=https://pyimg.co/ehnlf target=_blank>Sharma, A. “Introduction to Autoencoders,” PyImageSearch, P. Chugh, A. R. Gosthipaty, S. Huot, K. Kidriavsteva, and R. Raha, eds., 2023</a>.&nbsp;<a class=footnote-backref href=#fnref:1 title="Jump back to footnote 1 in the text">↩</a><a class=footnote-backref href=#fnref2:1 title="Jump back to footnote 1 in the text">↩</a><a class=footnote-backref href=#fnref3:1 title="Jump back to footnote 1 in the text">↩</a></p> </li> <li id=fn:2> <p><a href=https://www.v7labs.com/blog/autoencoders-guide target=_blank>Bandyopadhyay, H. "What is an autoencoder and how does it work? Learn about most common types of autoencoders and their applications in machine learning."</a>.&nbsp;<a class=footnote-backref href=#fnref:2 title="Jump back to footnote 2 in the text">↩</a><a class=footnote-backref href=#fnref2:2 title="Jump back to footnote 2 in the text">↩</a></p> </li> <li id=fn:3> <p><a href=https://pyimg.co/7e4if target=_blank>Sharma, A. “A Deep Dive into Variational Autoencoders with PyTorch,” PyImageSearch, P. Chugh, A. R. Gosthipaty, S. Huot, K. Kidriavsteva, and R. Raha, eds., 2023</a>.&nbsp;<a class=footnote-backref href=#fnref:3 title="Jump back to footnote 3 in the text">↩</a></p> </li> <li id=fn:4> <p><a href=https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence target=_blank>Wikipedia - Kullback–Leibler divergence</a>.&nbsp;<a class=footnote-backref href=#fnref:4 title="Jump back to footnote 4 in the text">↩</a></p> </li> <li id=fn:5> <p><a href=https://www.geeksforgeeks.org/deep-learning/understanding-kl-divergence-in-pytorch/ target=_blank>GeeksforGeeks - Understanding KL Divergence in PyTorch</a>.&nbsp;<a class=footnote-backref href=#fnref:5 title="Jump back to footnote 5 in the text">↩</a></p> </li> <li id=fn:6> <p><a href=https://www.datacamp.com/tutorial/variational-autoencoders target=_blank>DataCamp - Variational Autoencoders</a>.&nbsp;<a class=footnote-backref href=#fnref:6 title="Jump back to footnote 6 in the text">↩</a></p> </li> </ol> </div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 29, 2025 08:43:37 UTC">October 29, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 29, 2025 08:43:37 UTC">October 29, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Contributors> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"></path></svg> </span> <nav> <a href=mailto:hsandmann@ieee.org>Humberto Sandmann</a> </nav> </span> <span class=md-source-file__fact> <span class=md-icon title=Contributors> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"></path></svg> </span> <span>GitHub</span> <nav> <a href=https://github.com/hsandmann class=md-author title=@hsandmann> <img src="https://avatars.githubusercontent.com/u/20843348?v=4&size=72" alt=hsandmann> </a> </nav> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.copy", "content.code.select", "content.code.annotate", "content.tooltips", "navigation.instant", "navigation.instant.progress", "navigation.top", "navigation.path", "navigation.tracking"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../assets/_markdown_exec_pyodide.js></script> <script src=../../assets/javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../assets/javascripts/badge.js async></script> <script src=../../termynal.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>