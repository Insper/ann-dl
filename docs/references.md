Standford

CS224N: Natural Language Processing with Deep Learning - https://web.stanford.edu/class/cs224n/

8 years ago:

- Lecture 2 | Word Vector Representations: word2vec - https://www.youtube.com/watch?v=ERibwqs9p38
- Lecture 3 | GloVe: Global Vectors for Word Representation - https://www.youtube.com/watch?v=ASn7ExxLZws
- Lecture 4 | Word Window Classification and Neural Networks - https://www.youtube.com/watch?v=uc2_iwVqrRI
- Lecture 5 | Backpropagation and Project Advice - https://www.youtube.com/watch?v=isPiE-DBagM
- Lecture 6 | Dependency Parsing - https://www.youtube.com/watch?v=PVShkZgXznc
- Lecture 7 | Introduction to TensorFlow - https://www.youtube.com/watch?v=PicxU81owCs
- Lecture 8 | Recurrent Neural Networks and Language Models - https://www.youtube.com/watch?v=Keqep_PKrY8
- Lecture 9 | Machine Translation and Advanced Recurrent LSTMs and GRUs - https://www.youtube.com/watch?v=QuELiw8tbx8
- Review Session | Midterm Review - https://www.youtube.com/watch?v=2DYxT4OMAmw
- Lecture 10 | Neural Machine Translation and Models with Attention - https://www.youtube.com/watch?v=IxQtK2SjWWM
- Lecture 11 | Gated Recurrent Units and Further Topics in NMT - https://www.youtube.com/watch?v=6_MO12fPC-0
- Lecture 12 | End-to-End Models for Speech Processing - https://www.youtube.com/watch?v=3MjIkWxXigM
- Lecture 13 | Convolutional Neural Networks - https://www.youtube.com/watch?v=Lg6MZw_OOLI
- Lecture 14 | Tree Recursive Neural Networks and Constituency Parsing - https://www.youtube.com/watch?v=RfwgqPkWZ1w
- Lecture 15 | Coreference Resolution - https://www.youtube.com/watch?v=rpwEWLaueRk
- Lecture 16 | Dynamic Neural Networks for Question Answering - https://www.youtube.com/watch?v=T3octNTE7Is
- Lecture 17 | Issues in NLP and Possible Architectures for NLP - https://www.youtube.com/watch?v=B4v545V3Dq0
- Lecture 18 | Tackling the Limits of Deep Learning for NLP - https://www.youtube.com/watch?v=JYwNmSe4HqE

https://atcold.github.io/didactics.html
https://atcold.github.io/NYU-DLSP20/
https://web.stanford.edu/~jurafsky/slp3/ed3book_Jan25.pdf
https://web.stanford.edu/~jurafsky/slp3/
https://machinelearning.apple.com/research/illusion-of-thinking

Learning Visual N-Grams from Web Data https://arxiv.org/pdf/1612.09161
https://nlp.stanford.edu/projects/glove/

https://en.wikipedia.org/wiki/Diffusion_model
https://proceedings.mlr.press/v37/sohl-dickstein15.pdf


toy problems:
https://github.com/eddielo91/toy-problems


https://en.wikipedia.org/wiki/Artificial_intelligence

Reunião: 2025-05-12

Fazer cálculo de derivada parcial: Newton Raphson, gradiente descendente, etc.

Teorica ou prática?

Implementação prática com TensorFlow e PyTorch.


- NLP - PyTorch - Transformers (MLP) - Glove - Word2Vec - BERT - GPT - Cosine similarity - Embeddings - Transfer learning
- Visão computacional - Keras
- Machine learning (tudo menos ANN)

- Deep learning -> DEcisoes de ADAM, SGD, etc. RoC, Métricas de avaliação,Overfitting, etc. Batch or online. Large datasets. GPU / CPU

two clusters: 

Loop de treinamento - forward pass, loss function, backward pass, update weights. 

Por que multiplos layers? Residual, normalizantion, dropout (outros), etc.

PrairieLearn

Diffusion models - GANs - VAE - Energy-based models


${type??''} ${route??''} ${number??''}  ${additional??''} - ${neighborhood??''}


https://harvard-iacs.github.io/2022-CS109B/
https://harvard-iacs.github.io/2019-CS109B/labs/lab11/GANS/
https://docs.google.com/spreadsheets/d/1Ei_L9e8nLdz5IbZ26Gr7YeE7wpQU27qjE99CD1DiaUM/edit?gid=1450132264#gid=1450132264